\chapter{Pamäťový model}

Pri časovej analýze algoritmov sa zvyčajne používa takzvaný \RAM (skratka z anglického \emph{Random-Access Machine}, stroj s náhodným prístupom k pamäti), v ktorom sa predpokladá možnosť pristupovať k ľubovolnému úseku pamäte v konštantnom čase. To znamená, že vo výslednej asymptotickej analýze počítame len počet vykonaných operácií.

V skutočnosti však moderné počítače využívajú niekoľko úrovňovú pamäťovú hierarchiu \citep{drepper2007every}. Tá sa typicky skladá z registrov a troch úrovní \cache (vyrovnávacej pamäte) priamo na procesore, následne z hlavnej operačnej pamäte a disku\todo{referencie}. V tomto poradí sú tieto úrovne zoradené od najrýchlejšej a najmenšej (odozva rádovo \SI{1}{\nano\second}, kapacita \SI{64}{\kibi\byte}) až po najpomalšiu ale najväčšiu (odozva od \SI{100}{\micro\second} po \SI{10}{\milli\second} podľa typu\footnote{Klasické pevné disky (HDD) alebo disky bez pohyblivých častí (SSD)}, kapacita rádovo \SI{1}{\tebi\byte}). Približné hodnoty pre všetky úrovne sú v tabuľke \ref{tbl:memory-levels}.

\begin{table}
    \centering
    \caption{Približné parametre rôznych úrovní pamäte. Hodnoty troch úrovní \cache na procesore (L1, L2 a L3) sú pre mikroarchitektúru Intel Haswell. \citep{inteloptimize}}
    \label{tbl:memory-levels}
    \begin{threeparttable}
        \begin{tabular}{r r l}
            \toprule
            \textbf{Úroveň} & \textbf{Veľkosť} & \textbf{Odozva} \\ \toprule
            L1 & \SI{64}{\kibi\byte} & 4clk\tnote{1} $\approx$ \SI{1}{\nano\second} \\
            L2 & \SI{256}{\kibi\byte} & 11clk\tnote{1} $\approx$ \SI{4}{\nano\second} \\
            L3 & \SI[parse-numbers=false]{2\mbox{--}20}{\mebi\byte} & 36clk\tnote{1} $\approx$ \SI{12}{\nano\second} \\ \midrule
            RAM & $\approx$ \SI{8}{\gibi\byte} & $\approx$ \SI{100}{\nano\second} \\
            Disk & $\approx$ \SI{1}{\tebi\byte} & $\approx$ \SI[parse-numbers=false]{0.1\mbox{--}10}{\milli\second} \\
            \bottomrule
        \end{tabular}
        \begin{tablenotes}
            \item[1] Počet cyklov procesora, uvedené časové aproximácie pri \SI{3}{\giga\hertz}.
        \end{tablenotes}
    \end{threeparttable}
\end{table}
% TODO: tabulka - pridat rychlost, asociativitu, velkost bloku, pocet blokov, ...

% Praktickým dôvodom pre túto hierarchiu je cena a jednoduchosť výroby.
% TODO: 1ns * c = 30cm, limit

Dôsledkom tejto hierarchie je závislosť výslednej rýchlosti algoritmu od jeho prístupov k pamäti. Operácie, ktoré využívajú dáta uložene na disku potrvajú dlhšie ako tie, ktoré využívajú iba dáta v registroch. V skutočnosti sa tieto dáta postupne presunú z disku do hlavnej pamäte, do \cache na procesore a napokon do registrov. Následne sa môže požadovaná operácia vykonať rovnako rýchlo ako v druhom prípade, avšak nejaký čas bol algoritmus nečinný a čakalo sa na presun dát. Pre všetky susedné dvojice pamäťových úrovní teda slúži tá menšia a rýchlejšia ako vyrovnávacia pamäť pre tú väčšiu a pomalšiu. 

\section{External-memory model} \label{sec:extmem}
Spôsobom ako zohľadniť tieto skutočnosti pri analýze algoritmov je takzvaný \emph{external-memory model} (model externej pamäte), nazývaný tiež \emph{I/O model} alebo \emph{cache-aware model} \citep{aggarwal1988input}. Ten popisuje pamäť skladajúcu sa z dvoch častí (obrázok \ref{fig:exmem_model}), ktoré voláme \cache a \disk.

Všetky výpočty prebiehajú nad dátami v \cache, ktorá má obmedzenú veľkosť. Ostatné dáta sú uložené na disku neobmedzenej veľkosti, no nemôžeme s nimi priamo manipulovať a je ich potrebné najskôr preniesť do \cache. V samotnej analýze algoritmov potom počítame počet týchto prenosov z disku do \cache a naopak.

Samotné presuny sú realizované v \emph{blokoch} pamäte veľkosti $B$. Disk aj \cache sa skladajú z takýchto blokov a za jednu operáciu považujeme presun jedného bloku medzi nimi. \Cache má obmedzenú veľkosť $M$ a skladá sa teda z $\frac{M}{B}$ blokov.  

\begin{figure}
    \centering
    \resizebox{0.8\textwidth}{!}{%
        \input{figures/memory_model/extmem}    
    }
    \caption{External-memory model}
    \label{fig:exmem_model}
\end{figure}

\subsection{Cache-aware algoritmy}
Pokiaľ poznáme parametre $B$ a $M$, môžeme skonštruovať algoritmus, ktorý bude túto dvojicu pamätí využívať efektívne. Takéto algoritmy voláme \aware (uvedomujúci si \cache). Súčasťou tohto algoritmu by bolo explicitné spravovanie presunov pamäte - je potrebné riešiť čítanie blokov z disku a ich umiestňovanie do \cache, nahrádzanie blokov v \cache pri zaplnení a spätný zápis blokov na disk.

% TODO asociativita

Tento model tiež popisuje len dve úrovne pamäte a teda funguje efektívne len pre danú susednú dvojicu, pre ktorú ho na základe znalosti parametrov optimalizujeme. V moderných systémoch ale máme takýchto dvojíc niekoľko. Keby sme poznali parametre pre všetky tieto dvojice môžeme zovšeobecniť tento model pre viac úrovní a explicitne riešiť presun blokov medzi nimi. Takto sa však samotná správa pamäte potenciálne stáva komplikovanejším problémom ako pôvodný algoritmus.


\section{Cache-oblivious model}
Riešením týchto problémov je \emph{cache-oblivious model} (na \cache nedbajúci), v ktorom uvažujeme rovnakú dvoj-úrovňovú pamäť zloženú z disku a \cache \citep{frigo1999cache,prokop1999cache}. Na rozdiel od \aware modelu však algoritmus nepozná parametre $B$ a $M$. Pokiaľ sa nám napriek tomu podarí navrhnúť algoritmus, ktorý vykonáva (asymptoticky) rovnaký počet pamäťových presunov ako \aware algoritmus, bude bežať efektívne pre ľubovolné takéto parametre.

Takéto algoritmy majú na rozdiel od \aware algoritmov v \extmem modely mnohé výhody. Samotná implementácia algoritmu nemôže explicitne riešiť presun blokov pokiaľ nepozná veľkosť bloku ani koľko blokov môže do \cache uložiť. Táto úloha zostane ponechaná na nižšiu vrstvu (operačný systém resp. hardware v prípade \cache na procesore) - algoritmus bude pristupovať k pamäti priamo bez ohľadu na to, či sa nachádza v \cache alebo nie a v prípade potreby prebehnú nutné prenosy na nižšej úrovni (z pohľadu algoritmu) automaticky.

Ďalšou výhodou je automatická optimalizácia pre dané parametre. V prípade \aware algoritmov môže byť problémom získať presné hodnoty týchto parametrov a potrebné pri ich zmene upraviť algoritmus. Vývoj algoritmu, ktorý bude fungovať na rozličných architektúrach, môže byť problematický.

V neposlednom rade bude takýto \obliv algoritmus efektívny medzi každou dvojicou susedných úrovní. Vzhľadom na to, že hodnoty parametrov nepozná, musí pre ľubovolnú takú dvojicu pracovať rovnako efektívne.

% TODO assumptions (replacement + associativity)
% TODO \cache vs cache (+ cache-obliv, ... ) - when to use \emph?

\subsection{Správa pamäte}
V momente keď sa \obliv algoritmus pokúsi o vykonanie operácie, ktorá potrebuje dáta mimo cache je potrebné ich najskôr z disku skopírovať. V prípade, že je v cache voľný blok tak je možné presunúť dáta bez nutnosti nahradenia. V opačnom prípade je však potrebné uvoľniť miesto tým, že sa vyberie blok z cache, v prípade, že bol upravený sa jeho obsah zapíše späť na disk a následne sa požadovaný blok z disku zapíše na jeho miesto v cache. Tento proces sa nazýva výmena stránok ({\em page replacement}), a algoritmus rozhodujúci, ktorý blok z cache odstrániť, voláme stratégia výmeny stránok ({\em page-replacement strategy}).

Ak by sa táto stratégia správala tak, že vždy odstráni blok, ktorý bude potrebný v ďalšom kroku algoritmu, tak by bolo zakaždým presúvať bloky medzi diskom a cache. To by znamenalo, že počet blokov, s ktorými v cache môžeme pracovať je $M/B = 1$. Ďalším problémom je \emph{asociatívnosť} cache - z praktických dôvodov je často možné daný blok z disku uložiť len na niekoľko pozícií v cache. Inak by bolo potrebné ukladať spolu s každým blokom jeho plnú adresu na disku, čo by redukovalo celkový počet blokov, ktoré sa do cache zmestia. Znížením asociativity je možné ukladať iba časť adresy, pričom zvyšok je implicitne určený pozíciou v cache. V prípade nízkej asociativity však môžu opäť nastať situácie, kedy je algoritmus schopný využiť iba malý počet blokov v cache.

Tieto problémy \obliv model obchádza predpokladom ideálnej cache - cache, ktorá je plne asociatívna (každý blok disku je možné uložiť v každom bloku cache) a používa optimálnu stratégiu výmeny stránok, ktorá vždy odstráni blok, ktorý bude potrebný najneskôr. Prvý predpoklad je síce v reálnych systémoch nepraktický, no z teoretického hľadiska je v poriadku. Druhý predpoklad je však nerealizovateľný, keďže by stratégia výmeny stránok musela predpovedať budúce kroky algoritmu. Nasledovné lemy však ukazujú, že bez týchto predpokladov na reálnom systéme s nízkou asociativitou a jednoduchou stratégiou výmeny stránok sa algoritmus zhorší len o konštantný faktor.

% TODO better translation - more exact + explicit corollaries?
% TODO change from 'lema' to 'tvrdenie' or something?
\begin{lema}
Algoritmus, ktorý v ideálnej cache veľkosti $M$ s blokmi veľkosti $B$ vykoná $T$ pamäťových operácií, vykoná najviac $2T$ pamäťových operácií v cache veľkosti $2M$ s blokmi veľkosti $B$ pri použití stratégie \emph{LRU} alebo \emph{FIFO}. \citep[Lemma 12]{frigo1999cache}
\end{lema}

\begin{lema}
Plne asociatívna cache veľkosti $M$ sa dá simulovať s použitím $\bigO{M}$ pamäte tak, že prístup ku každému bloku v cache zaberie v priemernom prípade $\bigO{1}$ času. \citep[Lemma 16]{frigo1999cache}
\end{lema}

Stratégia \emph{LRU} (least recently used) vyberá vždy blok, ktorý bol najdlhšie nepoužitý. Implementácia vyžaduje udržiavať si ku každému bloku počítadlo, ktoré sa pri prístupe nastaví na nulu a pri prístupe k iným blokom zvýši o jedna. Pri potrebe uvoľniť miesto v cache vyberieme blok s najväčšou hodnotou počítadla - ten, ku ktorému najdlhšie nebol prístup.

Stratégia \emph{FIFO} (first in, first out) je ešte jednoduchšia - bloky sú udržiavame zoradené podla poradia ich vloženia do cache. Keď vyberáme blok na odstránenie tak vezmeme ten, ktorý bol pridaný najskôr a teda je na začiatku tohto usporiadania.